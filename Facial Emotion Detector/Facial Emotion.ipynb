{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28273 images belonging to 6 classes.\n",
      "Found 3534 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "num_classes = 6\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = './fer2013/train'\n",
    "validation_data_dir = './fer2013/validation'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      shear_range=0.3,\n",
    "      zoom_range=0.3,\n",
    "      width_shift_range=0.4,\n",
    "      height_shift_range=0.4,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saksham_nuclear_pc/anaconda3/envs/cv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/saksham_nuclear_pc/anaconda3/envs/cv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,102\n",
      "Trainable params: 1,325,926\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer=\"he_normal\",\n",
    "                 input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #2: second CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #3: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #4: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #5: first set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #6: second set of FC => RELU layers\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #7: softmax classifier\n",
    "model.add(Dense(num_classes, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1767/1767 [==============================] - 495s 280ms/step - loss: 1.4313 - acc: 0.4331 - val_loss: 1.4699 - val_acc: 0.4665\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.46995, saving model to /home/saksham_nuclear_pc/IEEE Mega Project 3.0/trained.h5\n",
      "Epoch 2/30\n",
      "1767/1767 [==============================] - 572s 323ms/step - loss: 1.3955 - acc: 0.4513 - val_loss: 1.5208 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.46995\n",
      "Epoch 3/30\n",
      "1767/1767 [==============================] - 576s 326ms/step - loss: 1.3818 - acc: 0.4550 - val_loss: 1.4480 - val_acc: 0.4613\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.46995 to 1.44803, saving model to /home/saksham_nuclear_pc/IEEE Mega Project 3.0/trained.h5\n",
      "Epoch 4/30\n",
      "1767/1767 [==============================] - 605s 342ms/step - loss: 1.3677 - acc: 0.4625 - val_loss: 1.5087 - val_acc: 0.4761\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.44803\n",
      "Epoch 5/30\n",
      "1767/1767 [==============================] - 574s 325ms/step - loss: 1.3508 - acc: 0.4729 - val_loss: 1.3756 - val_acc: 0.4864\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.44803 to 1.37559, saving model to /home/saksham_nuclear_pc/IEEE Mega Project 3.0/trained.h5\n",
      "Epoch 6/30\n",
      "1767/1767 [==============================] - 584s 331ms/step - loss: 1.3349 - acc: 0.4772 - val_loss: 1.4428 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.37559\n",
      "Epoch 7/30\n",
      "1767/1767 [==============================] - 573s 324ms/step - loss: 1.3256 - acc: 0.4850 - val_loss: 1.3685 - val_acc: 0.4937\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.37559 to 1.36851, saving model to /home/saksham_nuclear_pc/IEEE Mega Project 3.0/trained.h5\n",
      "Epoch 8/30\n",
      "1767/1767 [==============================] - 590s 334ms/step - loss: 1.3228 - acc: 0.4841 - val_loss: 1.3549 - val_acc: 0.5023\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.36851 to 1.35486, saving model to /home/saksham_nuclear_pc/IEEE Mega Project 3.0/trained.h5\n",
      "Epoch 9/30\n",
      "1767/1767 [==============================] - 565s 320ms/step - loss: 1.3152 - acc: 0.4899 - val_loss: 1.4457 - val_acc: 0.4792\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.35486\n",
      "Epoch 10/30\n",
      "1767/1767 [==============================] - 583s 330ms/step - loss: 1.3041 - acc: 0.4912 - val_loss: 1.4180 - val_acc: 0.5173\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.35486\n",
      "Epoch 11/30\n",
      "1767/1767 [==============================] - 587s 332ms/step - loss: 1.3004 - acc: 0.4961 - val_loss: 1.4456 - val_acc: 0.4878\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.35486\n",
      "Epoch 12/30\n",
      "1767/1767 [==============================] - 570s 322ms/step - loss: 1.2831 - acc: 0.5005 - val_loss: 1.4693 - val_acc: 0.4912\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.35486\n",
      "Epoch 13/30\n",
      "1767/1767 [==============================] - 561s 318ms/step - loss: 1.2835 - acc: 0.5059 - val_loss: 1.3737 - val_acc: 0.5179\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.35486\n",
      "Epoch 14/30\n",
      "1767/1767 [==============================] - 573s 324ms/step - loss: 1.2758 - acc: 0.5073 - val_loss: 1.4714 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.35486\n",
      "Epoch 15/30\n",
      "1767/1767 [==============================] - 572s 324ms/step - loss: 1.2657 - acc: 0.5174 - val_loss: 1.4004 - val_acc: 0.5156\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.35486\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"/home/saksham_nuclear_pc/IEEE Mega Project 3.0/trained.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 7,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 7, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 28273\n",
    "nb_validation_samples = 3534\n",
    "epochs = 30\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3534 images belonging to 6 classes.\n",
      "Confusion Matrix\n",
      "[[212  33  31  48 145  22]\n",
      " [134  60  41  68 148  77]\n",
      " [ 18   9 759  35  34  24]\n",
      " [105  31 156 126 140  68]\n",
      " [ 74  20  45 135 311   9]\n",
      " [ 19  33  29  21  12 302]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.38      0.43      0.40       491\n",
      "        Fear       0.32      0.11      0.17       528\n",
      "       Happy       0.72      0.86      0.78       879\n",
      "     Neutral       0.29      0.20      0.24       626\n",
      "         Sad       0.39      0.52      0.45       594\n",
      "    Surprise       0.60      0.73      0.66       416\n",
      "\n",
      "    accuracy                           0.50      3534\n",
      "   macro avg       0.45      0.48      0.45      3534\n",
      "weighted avg       0.47      0.50      0.47      3534\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "nb_train_samples = 28273\n",
    "nb_validation_samples = 3534\n",
    "\n",
    "# We need to recreate our validation generator with shuffle = false\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
